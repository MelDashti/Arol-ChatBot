{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 39.71223021582734,
  "eval_steps": 200,
  "global_step": 2760,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.7194244604316546,
      "grad_norm": 0.8393882513046265,
      "learning_rate": 0.00015,
      "loss": 1.2469,
      "step": 50
    },
    {
      "epoch": 1.4388489208633093,
      "grad_norm": 0.7204909324645996,
      "learning_rate": 0.0003,
      "loss": 0.2899,
      "step": 100
    },
    {
      "epoch": 2.158273381294964,
      "grad_norm": 7.4583282470703125,
      "learning_rate": 0.00029436090225563904,
      "loss": 0.2418,
      "step": 150
    },
    {
      "epoch": 2.8776978417266186,
      "grad_norm": 0.5172481536865234,
      "learning_rate": 0.00028872180451127816,
      "loss": 0.2007,
      "step": 200
    },
    {
      "epoch": 2.8776978417266186,
      "eval_loss": 0.3213096261024475,
      "eval_runtime": 6.4877,
      "eval_samples_per_second": 15.722,
      "eval_steps_per_second": 2.004,
      "step": 200
    },
    {
      "epoch": 3.597122302158273,
      "grad_norm": 0.46654126048088074,
      "learning_rate": 0.0002830827067669173,
      "loss": 0.1683,
      "step": 250
    },
    {
      "epoch": 4.316546762589928,
      "grad_norm": 0.39586928486824036,
      "learning_rate": 0.0002774436090225564,
      "loss": 0.1518,
      "step": 300
    },
    {
      "epoch": 5.0359712230215825,
      "grad_norm": 0.3229016065597534,
      "learning_rate": 0.00027180451127819546,
      "loss": 0.1365,
      "step": 350
    },
    {
      "epoch": 5.755395683453237,
      "grad_norm": 0.5471691489219666,
      "learning_rate": 0.0002661654135338346,
      "loss": 0.1204,
      "step": 400
    },
    {
      "epoch": 5.755395683453237,
      "eval_loss": 0.325636625289917,
      "eval_runtime": 5.1079,
      "eval_samples_per_second": 19.969,
      "eval_steps_per_second": 2.545,
      "step": 400
    },
    {
      "epoch": 6.474820143884892,
      "grad_norm": 0.394203245639801,
      "learning_rate": 0.0002605263157894737,
      "loss": 0.1095,
      "step": 450
    },
    {
      "epoch": 7.194244604316546,
      "grad_norm": 0.4107261300086975,
      "learning_rate": 0.00025488721804511276,
      "loss": 0.1056,
      "step": 500
    },
    {
      "epoch": 7.913669064748201,
      "grad_norm": 0.3334469497203827,
      "learning_rate": 0.0002492481203007519,
      "loss": 0.0998,
      "step": 550
    },
    {
      "epoch": 8.633093525179856,
      "grad_norm": 0.49192148447036743,
      "learning_rate": 0.00024360902255639094,
      "loss": 0.0923,
      "step": 600
    },
    {
      "epoch": 8.633093525179856,
      "eval_loss": 0.3790997862815857,
      "eval_runtime": 5.1431,
      "eval_samples_per_second": 19.832,
      "eval_steps_per_second": 2.528,
      "step": 600
    },
    {
      "epoch": 9.352517985611511,
      "grad_norm": 0.5631255507469177,
      "learning_rate": 0.00023796992481203005,
      "loss": 0.0889,
      "step": 650
    },
    {
      "epoch": 10.071942446043165,
      "grad_norm": 0.4911055564880371,
      "learning_rate": 0.00023233082706766915,
      "loss": 0.086,
      "step": 700
    },
    {
      "epoch": 10.79136690647482,
      "grad_norm": 0.3074039816856384,
      "learning_rate": 0.00022669172932330824,
      "loss": 0.0774,
      "step": 750
    },
    {
      "epoch": 11.510791366906474,
      "grad_norm": 0.21118037402629852,
      "learning_rate": 0.00022105263157894733,
      "loss": 0.0746,
      "step": 800
    },
    {
      "epoch": 11.510791366906474,
      "eval_loss": 0.37876731157302856,
      "eval_runtime": 5.1334,
      "eval_samples_per_second": 19.87,
      "eval_steps_per_second": 2.532,
      "step": 800
    },
    {
      "epoch": 12.23021582733813,
      "grad_norm": 0.3466273546218872,
      "learning_rate": 0.00021541353383458647,
      "loss": 0.0729,
      "step": 850
    },
    {
      "epoch": 12.949640287769784,
      "grad_norm": 0.22445829212665558,
      "learning_rate": 0.00020977443609022556,
      "loss": 0.0693,
      "step": 900
    },
    {
      "epoch": 13.66906474820144,
      "grad_norm": 0.19922959804534912,
      "learning_rate": 0.00020413533834586463,
      "loss": 0.0651,
      "step": 950
    },
    {
      "epoch": 14.388489208633093,
      "grad_norm": 0.19710630178451538,
      "learning_rate": 0.00019849624060150372,
      "loss": 0.0635,
      "step": 1000
    },
    {
      "epoch": 14.388489208633093,
      "eval_loss": 0.41522887349128723,
      "eval_runtime": 5.1216,
      "eval_samples_per_second": 19.916,
      "eval_steps_per_second": 2.538,
      "step": 1000
    },
    {
      "epoch": 15.107913669064748,
      "grad_norm": 0.2688640356063843,
      "learning_rate": 0.00019285714285714286,
      "loss": 0.0639,
      "step": 1050
    },
    {
      "epoch": 15.827338129496402,
      "grad_norm": 0.2332374006509781,
      "learning_rate": 0.00018721804511278195,
      "loss": 0.0613,
      "step": 1100
    },
    {
      "epoch": 16.546762589928058,
      "grad_norm": 0.20795118808746338,
      "learning_rate": 0.00018157894736842105,
      "loss": 0.0584,
      "step": 1150
    },
    {
      "epoch": 17.26618705035971,
      "grad_norm": 0.17897218465805054,
      "learning_rate": 0.00017593984962406014,
      "loss": 0.0599,
      "step": 1200
    },
    {
      "epoch": 17.26618705035971,
      "eval_loss": 0.41451606154441833,
      "eval_runtime": 5.1349,
      "eval_samples_per_second": 19.864,
      "eval_steps_per_second": 2.532,
      "step": 1200
    },
    {
      "epoch": 17.985611510791365,
      "grad_norm": 0.167461559176445,
      "learning_rate": 0.00017030075187969925,
      "loss": 0.0583,
      "step": 1250
    },
    {
      "epoch": 18.705035971223023,
      "grad_norm": 0.162746861577034,
      "learning_rate": 0.00016466165413533835,
      "loss": 0.0572,
      "step": 1300
    },
    {
      "epoch": 19.424460431654676,
      "grad_norm": 0.2825809121131897,
      "learning_rate": 0.00015902255639097744,
      "loss": 0.058,
      "step": 1350
    },
    {
      "epoch": 20.14388489208633,
      "grad_norm": 0.11077196151018143,
      "learning_rate": 0.00015338345864661653,
      "loss": 0.0573,
      "step": 1400
    },
    {
      "epoch": 20.14388489208633,
      "eval_loss": 0.4232720732688904,
      "eval_runtime": 5.1469,
      "eval_samples_per_second": 19.818,
      "eval_steps_per_second": 2.526,
      "step": 1400
    },
    {
      "epoch": 20.863309352517987,
      "grad_norm": 0.1282869428396225,
      "learning_rate": 0.00014774436090225562,
      "loss": 0.0555,
      "step": 1450
    },
    {
      "epoch": 21.58273381294964,
      "grad_norm": 0.23958688974380493,
      "learning_rate": 0.0001421052631578947,
      "loss": 0.0544,
      "step": 1500
    },
    {
      "epoch": 22.302158273381295,
      "grad_norm": 0.1393081396818161,
      "learning_rate": 0.00013646616541353383,
      "loss": 0.0524,
      "step": 1550
    },
    {
      "epoch": 23.02158273381295,
      "grad_norm": 0.09362688660621643,
      "learning_rate": 0.00013082706766917292,
      "loss": 0.0534,
      "step": 1600
    },
    {
      "epoch": 23.02158273381295,
      "eval_loss": 0.45009279251098633,
      "eval_runtime": 5.1286,
      "eval_samples_per_second": 19.888,
      "eval_steps_per_second": 2.535,
      "step": 1600
    },
    {
      "epoch": 23.741007194244606,
      "grad_norm": 0.13627149164676666,
      "learning_rate": 0.000125187969924812,
      "loss": 0.0501,
      "step": 1650
    },
    {
      "epoch": 24.46043165467626,
      "grad_norm": 0.101954385638237,
      "learning_rate": 0.00011954887218045111,
      "loss": 0.0522,
      "step": 1700
    },
    {
      "epoch": 25.179856115107913,
      "grad_norm": 0.10645272582769394,
      "learning_rate": 0.00011390977443609022,
      "loss": 0.0514,
      "step": 1750
    },
    {
      "epoch": 25.899280575539567,
      "grad_norm": 0.12041350454092026,
      "learning_rate": 0.00010827067669172931,
      "loss": 0.0513,
      "step": 1800
    },
    {
      "epoch": 25.899280575539567,
      "eval_loss": 0.45750194787979126,
      "eval_runtime": 5.1294,
      "eval_samples_per_second": 19.885,
      "eval_steps_per_second": 2.534,
      "step": 1800
    },
    {
      "epoch": 26.618705035971225,
      "grad_norm": 0.11100322008132935,
      "learning_rate": 0.00010263157894736841,
      "loss": 0.0508,
      "step": 1850
    },
    {
      "epoch": 27.33812949640288,
      "grad_norm": 0.2608374059200287,
      "learning_rate": 9.69924812030075e-05,
      "loss": 0.05,
      "step": 1900
    },
    {
      "epoch": 28.057553956834532,
      "grad_norm": 0.10056965798139572,
      "learning_rate": 9.135338345864661e-05,
      "loss": 0.0507,
      "step": 1950
    },
    {
      "epoch": 28.776978417266186,
      "grad_norm": 0.11281926929950714,
      "learning_rate": 8.57142857142857e-05,
      "loss": 0.0484,
      "step": 2000
    },
    {
      "epoch": 28.776978417266186,
      "eval_loss": 0.4889112114906311,
      "eval_runtime": 5.1362,
      "eval_samples_per_second": 19.859,
      "eval_steps_per_second": 2.531,
      "step": 2000
    },
    {
      "epoch": 29.496402877697843,
      "grad_norm": 0.09556588530540466,
      "learning_rate": 8.00751879699248e-05,
      "loss": 0.0487,
      "step": 2050
    },
    {
      "epoch": 30.215827338129497,
      "grad_norm": 0.09272675216197968,
      "learning_rate": 7.44360902255639e-05,
      "loss": 0.0492,
      "step": 2100
    },
    {
      "epoch": 30.93525179856115,
      "grad_norm": 0.11625434458255768,
      "learning_rate": 6.8796992481203e-05,
      "loss": 0.0487,
      "step": 2150
    },
    {
      "epoch": 31.654676258992804,
      "grad_norm": 0.10303428024053574,
      "learning_rate": 6.315789473684209e-05,
      "loss": 0.0479,
      "step": 2200
    },
    {
      "epoch": 31.654676258992804,
      "eval_loss": 0.5271005034446716,
      "eval_runtime": 5.1262,
      "eval_samples_per_second": 19.898,
      "eval_steps_per_second": 2.536,
      "step": 2200
    },
    {
      "epoch": 32.37410071942446,
      "grad_norm": 0.10247574001550674,
      "learning_rate": 5.7518796992481194e-05,
      "loss": 0.0481,
      "step": 2250
    },
    {
      "epoch": 33.093525179856115,
      "grad_norm": 0.08465955406427383,
      "learning_rate": 5.187969924812029e-05,
      "loss": 0.0481,
      "step": 2300
    },
    {
      "epoch": 33.81294964028777,
      "grad_norm": 0.08915325254201889,
      "learning_rate": 4.624060150375939e-05,
      "loss": 0.047,
      "step": 2350
    },
    {
      "epoch": 34.53237410071942,
      "grad_norm": 0.097284235060215,
      "learning_rate": 4.060150375939849e-05,
      "loss": 0.0469,
      "step": 2400
    },
    {
      "epoch": 34.53237410071942,
      "eval_loss": 0.5422183275222778,
      "eval_runtime": 5.1333,
      "eval_samples_per_second": 19.87,
      "eval_steps_per_second": 2.533,
      "step": 2400
    },
    {
      "epoch": 35.25179856115108,
      "grad_norm": 0.09691179543733597,
      "learning_rate": 3.496240601503759e-05,
      "loss": 0.0474,
      "step": 2450
    },
    {
      "epoch": 35.97122302158273,
      "grad_norm": 0.0946117490530014,
      "learning_rate": 2.9323308270676686e-05,
      "loss": 0.0467,
      "step": 2500
    },
    {
      "epoch": 36.69064748201439,
      "grad_norm": 0.09406868368387222,
      "learning_rate": 2.3684210526315787e-05,
      "loss": 0.0463,
      "step": 2550
    },
    {
      "epoch": 37.410071942446045,
      "grad_norm": 0.09787575900554657,
      "learning_rate": 1.8045112781954885e-05,
      "loss": 0.0464,
      "step": 2600
    },
    {
      "epoch": 37.410071942446045,
      "eval_loss": 0.5546714663505554,
      "eval_runtime": 5.1294,
      "eval_samples_per_second": 19.885,
      "eval_steps_per_second": 2.534,
      "step": 2600
    },
    {
      "epoch": 38.1294964028777,
      "grad_norm": 0.09719839692115784,
      "learning_rate": 1.2406015037593982e-05,
      "loss": 0.0462,
      "step": 2650
    },
    {
      "epoch": 38.84892086330935,
      "grad_norm": 0.09041725099086761,
      "learning_rate": 6.766917293233082e-06,
      "loss": 0.0452,
      "step": 2700
    },
    {
      "epoch": 39.568345323741006,
      "grad_norm": 0.09987153112888336,
      "learning_rate": 1.1278195488721803e-06,
      "loss": 0.0455,
      "step": 2750
    }
  ],
  "logging_steps": 50,
  "max_steps": 2760,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 40,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.52001607397335e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
